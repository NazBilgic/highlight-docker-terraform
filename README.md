#  NCAA Game Highlights Processor

A full-stack DevOps project that collects and processes NCAA basketball game highlights using a Docker container, RapidAPI, AWS MediaConvert, and stores results in AWS S3. Infrastructure is provisioned using Terraform for scalability and repeatability.

---

##  Features

-  Fetches NCAA basketball video highlights from [RapidAPI](https://rapidapi.com/)
-  Stores highlight metadata and videos in AWS S3
-  Processes videos with AWS MediaConvert (resolution, codec, bitrate)
-  Runs inside a Docker container
-  Deployable using Infrastructure as Code (Terraform)
-  Uses AWS Secrets Manager and environment variables for secure API key storage
-  Supports local and cloud-based execution

---

##  Project Structure

src/
â”œâ”€â”€ config.py
â”œâ”€â”€ fetch.py
â”œâ”€â”€ process_one_video.py
â”œâ”€â”€ mediaconvert_process.py
â”œâ”€â”€ run_all.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â””â”€â”€ terraform/
â”œâ”€â”€ main.tf
â”œâ”€â”€ variables.tf
â”œâ”€â”€ secrets.tf
â”œâ”€â”€ iam.tf
â”œâ”€â”€ ecr.tf
â”œâ”€â”€ ecs.tf
â”œâ”€â”€ s3.tf
â”œâ”€â”€ outputs.tf
â””â”€â”€ container_definitions.tpl


---

## Quick Start

### 1ï¸âƒ£ Clone the repo

```bash
git clone https://github.com/NazBilgic/NCAAGameHighlights.git
cd src
2ï¸âƒ£ Create a RapidAPI account and get an API key
We use NCAA Basketball highlights (free in the basic plan).

3ï¸âƒ£ Store API Key in AWS Secrets Manager
bash
Copy
Edit
aws secretsmanager create-secret \
  --name my-api-key \
  --description "API key for Sport Highlights API" \
  --secret-string '{"api_key":"YOUR_ACTUAL_API_KEY"}' \
  --region us-east-1
4ï¸âƒ£ Set Up IAM Role
Create an IAM role named HighlightProcessorRole with these policies:

AmazonS3FullAccess

MediaConvertFullAccess

AmazonEC2ContainerRegistryFullAccess

Trust Policy:

json
Copy
Edit
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": [
          "ec2.amazonaws.com",
          "ecs-tasks.amazonaws.com",
          "mediaconvert.amazonaws.com"
        ]
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
5ï¸âƒ£ Prepare .env file
env

RAPIDAPI_KEY=your_api_key
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
S3_BUCKET_NAME=your_bucket_name
MEDIACONVERT_ENDPOINT=https://abc123.mediaconvert.us-east-1.amazonaws.com
MEDIACONVERT_ROLE_ARN=arn:aws:iam::123456789012:role/HighlightProcessorRole
bash

chmod 600 .env
6ï¸âƒ£ Run Locally in Docker
bash

docker build -t highlight-processor .
docker run --env-file .env highlight-processor
âœ… You should now see:

basketball_highlight.json in S3

Raw and processed videos uploaded to s3://<bucket>/videos/ and processed_videos/

ğŸ§° Terraform Deployment (Bonus)
bash
Copy
Edit
cd terraform
terraform init
terraform validate
terraform plan
terraform apply -var-file="terraform.dev.tfvars"
Push Docker Image to ECR
bash
Copy
Edit
docker build -t highlight-pipeline .
docker tag highlight-pipeline:latest <AWS_ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com/highlight-pipeline:latest

aws ecr get-login-password --region us-east-1 | \
  docker login --username AWS --password-stdin <AWS_ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com

docker push <AWS_ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com/highlight-pipeline:latest


 What I Learned
Working with Docker + AWS Services (S3, IAM, ECS, MediaConvert)

Using Terraform for reproducible infrastructure

Secure secret management with AWS Secrets Manager

Automating highlight collection pipelines




